# ğŸ“Š Proyecto BaseDatosBigData

Este proyecto implementa un **pipeline ETL (Extract, Transform, Load)** en Python para trabajar con datos masivos. La arquitectura sigue un enfoque modular, separando la configuraciÃ³n, extracciÃ³n, transformaciÃ³n y carga de datos en carpetas especÃ­ficas.

## ğŸ“‚ Estructura del Proyecto

```
BaseDatosBigData/
â”‚
â”œâ”€â”€ Config/                  # ConfiguraciÃ³n general
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ConfigBig.py
â”‚
â”œâ”€â”€ Extract/                 # MÃ³dulo de extracciÃ³n de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ BigDataExtract.py
â”‚
â”œâ”€â”€ Load/                    # MÃ³dulo de carga de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ BigDataLoad.py
â”‚
â”œâ”€â”€ Transform/               # MÃ³dulo de transformaciÃ³n de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ BigDataTransform.py
â”‚
â”œâ”€â”€ Pokemon.csv              # Dataset de ejemplo
â”œâ”€â”€ main.py                  # Script principal de ejecuciÃ³n del pipeline
â”œâ”€â”€ requirements.txt         # Dependencias necesarias
â””â”€â”€ README.md                # DocumentaciÃ³n del proyecto
```

## ğŸš€ Flujo ETL

1. **Extract (`Extract/`)**
   AquÃ­ se define la lÃ³gica para **leer los datos desde distintas fuentes** (archivos CSV, bases de datos, APIs, etc.).
   Ejemplo: en este proyecto se usa el archivo `Pokemon.csv`.

2. **Transform (`Transform/`)**
   AquÃ­ se realizan las operaciones de **limpieza, validaciÃ³n y transformaciÃ³n de datos**:

   * NormalizaciÃ³n de columnas.
   * EliminaciÃ³n de valores nulos o duplicados.
   * EstandarizaciÃ³n de tipos de datos.
   * AplicaciÃ³n de reglas de negocio.

3. **Load (`Load/`)**
   Finalmente, los datos procesados se **cargan en un destino** (base de datos, otro archivo CSV/Excel, o incluso almacenamiento en la nube).

4. **Config (`Config/`)**
   Contiene parÃ¡metros de configuraciÃ³n globales (rutas de archivos, credenciales, conexiones, etc.).

5. **main.py**
   Es el **punto de entrada del pipeline**. Desde aquÃ­ se ejecuta el flujo completo: **Extract â†’ Transform â†’ Load**.

## âš™ï¸ InstalaciÃ³n

1. Clona el repositorio:

   ```bash
   git clone <url-del-repo>
   cd BaseDatosBigData
   ```

2. Crea un entorno virtual y activa:

   ```bash
   python -m venv venv
   source venv/bin/activate   # En Linux/Mac
   venv\Scripts\activate      # En Windows
   ```

3. Instala las dependencias:

   ```bash
   pip install -r requirements.txt
   ```

## â–¶ï¸ EjecuciÃ³n

Ejecuta el pipeline completo desde `main.py`:

```bash
python main.py
```

## ğŸ“Œ PrÃ³ximos pasos

* Implementar un mÃ³dulo de **cleaning** dentro de `Transform/BigDataTransform.py` para limpiar datos de Excel o CSV (ejemplo: `Pokemon.csv`).
* Agregar logs para seguimiento de errores.
* Conectar con una base de datos real para la etapa de `Load`.

